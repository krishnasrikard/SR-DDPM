{
    "name": "SR_FFHQ_Pretrained_Finetune_AnimeF_10k_iters",
    "phase": "train", // train or val
    "gpu_ids": [
        1
    ],
    "path": { //set the path
        "log": "logs",
        "tb_logger": "tb_logger",
        "results": "results",
        "checkpoint": "checkpoint",
        "resume_state": "pre-trained-models/ffhq_pretrained_checkpoint-16-128/I640000_E37" //address for pretrained weights
    },
    "datasets": {
        "train": {
            "name": "Finetune-FFHQ-AnimeF",
            "mode": "HR", // need LR img 
            "dataroot": "dataset/AnimeF/sr3_16_128/train/",
            "datatype": "img", 
            "l_resolution": 16, // low resolution
            "r_resolution": 128, // high resolution
            "batch_size": 4, //batch size
            "num_workers": 20,
            "use_shuffle": true,
            "data_len": 4449 // -1 represents all data used in train; #44496 [total in train split for animeF]
        },
        "val": {
            "name": "AnimeF",
            "mode": "LRHR",
            "dataroot": "dataset/AnimeF/sr3_16_128/test/",
            "datatype": "img",
            "l_resolution": 16,
            "r_resolution": 128,
            "data_len": -1
        }
    },
    "model": {
        "which_model_G": "sr3",
        "finetune_norm": false,
        "unet": {
            "in_channel": 6,
            "out_channel": 3,
            "inner_channel": 64,
            "channel_multiplier": [
                1,
                2,
                4,
                8,
                8
            ],
            "attn_res": [
                16
            ],
            "res_blocks": 2,
            "dropout": 0.2
        },
        "beta_schedule": { 
            "train": {
                "schedule": "linear",
                "n_timestep": 2000, // total time steps
                "linear_start": 1e-6,
                "linear_end": 1e-2,
                "start_t":0, // start time step [for selective training of time steps]
                "end_t":2000 // end time step 
            },
            "val": {
                "schedule": "linear",
                "n_timestep": 2000,
                "linear_start": 1e-6,
                "linear_end": 1e-2,
                "start_t":0,
                "end_t":2000 
            }
        },
        "diffusion": {
            "image_size": 128,
            "channels": 3, 
            "conditional": true // unconditional generation
        }
    },
    "train": {
        "n_iter": 650000, // final iteration where training stops
        "val_freq": 1e3, // validate after every these train iterations
        "save_checkpoint_freq": 1e3, //save checkpoint after every these iterations
        "print_freq": 100, 
        "optimizer": {
            "type": "adam",
            "lr": 1e-4
        },
        "ema_scheduler": {
            "step_start_ema": 5000,
            "update_ema_every": 1,
            "ema_decay": 0.9999
        }
    }
}