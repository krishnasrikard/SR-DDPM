{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo File to walk through inference, finetuning, and training. \n",
    "\n",
    "\n",
    "folder: experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing required lib \n",
    "\n",
    "NOTE: skip if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirement.txt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference only: \n",
    "\n",
    "Pretrained - FFHQ \\\n",
    "Finetuned on - AnimeF \\\n",
    "On AnimeF samples.\n",
    "\n",
    "\n",
    "We have all the weights present here: \"\"\n",
    "\n",
    "##### Time steps: \n",
    "$0-200$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_20k_200T_230414_161859/checkpoint/I644000_E40\" \\\n",
    "$0-500$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_20k_500T_230414_140306/checkpoint/I644000_E40\" \\\n",
    "$0-1000$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_20k_1000T_proper_230414_115058/checkpoint/I644000_E40\" \\\n",
    "$1000-1500$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_20k_1000-1500T_230414_203103/checkpoint/I644000_E40\"  \\  \n",
    "$1500-2000$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_20k_1500-2000T_230421_145419/checkpoint/I644000_E40\" \\     \n",
    "$0-2000$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I650000_E45\" \\\n",
    "\n",
    "##### Iterations: \n",
    "$10K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I650000_E45\" \\   \n",
    "$30K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I670000_E59\" \\\n",
    "$70K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I710000_E88\" \\   \n",
    "$100K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I740000_E109\" \\ \n",
    "\n",
    "##### Limited data\n",
    "$10%$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_50k_datafraction_10perc_230421_155807/checkpoint/I650000_E109\" \\ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I740000_E109\"\n",
    "config_file = \"config/sr_sr3_16_128_AnimeF_infer.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python infer.py -c {} -w {}\".format(config_file, weight_path))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference only: \n",
    "\n",
    "Pretrained - AnimeF \\\n",
    "\n",
    "On AnimeF samples.\n",
    "\n",
    "\n",
    "##### Trained from scratch \n",
    "\n",
    "\"demo_model_weights/sr_AnimeF_scratch_230418_114151/checkpoint/I140000_E101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"demo_model_weights/sr_AnimeF_scratch_230418_114151/checkpoint/I140000_E101\"\n",
    "config_file = \"config/sr_sr3_16_128_AnimeF_infer.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python infer.py -c {} -w {}\".format(config_file, weight_path))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference only:\n",
    "\n",
    "Pretrained - FFHQ \\\n",
    "Finetune - AnimeF \\\n",
    "\n",
    "##### On FFHQ/CelebA-HQ samples. \n",
    "To check the catastrophic forgetting. \n",
    "\n",
    "##### various finetune steps:\n",
    "$4K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I650000_E45\" \\\n",
    "$10K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I650000_E45\" \\   \n",
    "$30K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I670000_E59\" \\\n",
    "$70K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I710000_E88\" \\   \n",
    "$100K$ : \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I740000_E109\" \\ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"demo_model_weights/sr_ffhq_AnimeF_finetune_230413_004414_100kMore_Iters_saved_each_10k/checkpoint/I740000_E109\"\n",
    "celebAHQ_config_file = \"config/sr_sr3_16_128_celebAHQ_infer.json\"\n",
    "ffhq_config_file = \"config/sr_sr3_16_128_ffhq_infer.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python infer.py -c {} -w {}\".format(celebAHQ_config_file, weight_path))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference only:\n",
    "\n",
    "Pretrained - FFHQ \\\n",
    "On CelebA-HQ samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"pre-trained-models/ffhq_pretrained_checkpoint-16-128/I640000_E37\"\n",
    "celebAHQ_config_file = \"config/sr_sr3_16_128_pre_FFHQ_celebAHQ_infer.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python infer.py -c {} -w {}\".format(celebAHQ_config_file, weight_path))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference only:\n",
    "\n",
    "Pretrained - Imagenet \\\n",
    "On Imagenet samples. (separate test samples)\n",
    "\n",
    "\"Image-Super-Resolution-via-Iterative-Refinement/experiments/sr_imagenet1k_230422_232406/checkpoint/I1000000\" \\ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"demo_model_weights/sr_imagenet1k_230422_232406/checkpoint/I1000000\"\n",
    "config_file = \"config/sr_sr3_16_128_imagenet_infer_imagenet.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python infer.py -c {} -w {}\".format(config_file, weight_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Only: \n",
    "\n",
    "Zeroshot - Pretrained Imagnet DDPM \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"DDNM\")\n",
    "if True:\n",
    "    os.system(\"python main.py --ni --simplified --config imagenet_256.yml --path_y 'exp/datasets/imagenet/imagenet' --eta 0.85 --deg 'sr_averagepooling' --deg_scale 4.0 --sigma_y 0 -i demo\")\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune: \n",
    "\n",
    "Pretrained - FFHQ \\\n",
    "Finetune on - AnimeF \n",
    "\n",
    "Will finetune for 10K iters. \n",
    "\n",
    "write details on how to change for various iters / time steps etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/sr_sr3_16_128_AnimeF.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python sr.py -p train -c {}\".format(config_file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune: \n",
    "\n",
    "Pretrained - FFHQ \\\n",
    "Finetune on - DF2K-OST\n",
    "\n",
    "Will finetune fo 10K iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/sr_sr3_16_128_DF2K.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python sr.py -p train -c {}\".format(config_file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train from scratch: \n",
    "\n",
    "On Imagenet for 10K iters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/sr_sr3_16_128_imagnet1k.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python sr.py -p train -c {}\".format(config_file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train from sractch:\n",
    "\n",
    "On AnimeF for 10K iters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/sr_sr3_16_128_AnimeF_scratch.json\"\n",
    "\n",
    "if True:\n",
    "    os.system(\"python sr.py -p train -c {}\".format(config_file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Getting PSNR and SSIM \n",
    "\n",
    "input the path of inferred samples : \"misc_results/sr_ffhq_AimeF_Finetuned_infer_celebhq_Iter_100K_results_230422_203929/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"misc_results/sr_ffhq_AimeF_Finetuned_infer_celebhq_Iter_100K_results_230422_203929/results\"\n",
    "if True:\n",
    "    os.system(\"python eval.py -p {}\".format(path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
